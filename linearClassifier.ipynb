{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Objective\n",
    "I'm going to create a linear regression classifier based on Andrew Ng's teachings before the linear algebra review... so hopefully that doesn't bite me in the butt. It's going to be using batch gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details\n",
    "- Scalable number of features (test up to 3)\n",
    "- Gradient Descent (batch)\n",
    "- Cost function (squared error cost function)\n",
    "- Regression classifier only\n",
    "- Manual learning rate (alpha)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "1) ~~I'm going to first import a standardized linear regression classifier from tensorflow, and configure it appropriately, then ensure i'm getting the proper output.~~ I will create the static training data and testing data.\n",
    "\n",
    "2) I'm going to build my version of the classifier in python, and work on it until I get the proper results.\n",
    "\n",
    "(#Test-driven development?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Results\n",
    "1) Greater Python familiarity\n",
    "\n",
    "~~2) Greater Tensorflow familiarity~~\n",
    "\n",
    "3) Greater fundamental ML familiarity\n",
    "\n",
    "4) Resume worthy material\n",
    "\n",
    "*I will be editing my material minimally to preserve the jouney of my project, think of it as a story =]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with importing everything needed\n",
    "from __future__ import division\n",
    "#import tensorflow as tf # for bonafide classifiers\n",
    "import numpy as np # matrices and calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1104049e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11148fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating data\n",
    "X = [1, 2, 3, 4, 5]\n",
    "Y = [2, 3, 4, 5, 6]\n",
    "Xtr = X[0:3]\n",
    "Ytr = Y[0:3]\n",
    "Xte = X[3:5]\n",
    "Yte = Y[3:5]\n",
    "\n",
    "import matplotlib.pyplot as plt # to visualize data, I know it's bad practice just documenting the journey\n",
    "plt.figure(1)\n",
    "plt.title(\"All data\")\n",
    "plt.scatter(Xtr,Ytr, label=\"training\")\n",
    "plt.scatter(Xte,Yte, label=\"testing\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title(\"Perfect predictor for dataset\")\n",
    "plt.scatter(Xtr,Ytr, label=\"training\")\n",
    "plt.scatter(Xte,Yte, label=\"testing\")\n",
    "plt.plot(X,Y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "At this point (after 3hr of trying to brute force Tensorflow instead of understanding it) I realized how much time it was going to take to dive deep into Tensorflow. So instead decided to choose another option to save time. Keras didn't do the trick either- but at least I got it working. I thought if I just made one layer it might act like a linear classifier, but I was very very wrong ...\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that perfect linear predictor would have the weights of: theta0 = 1, theta1 = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_predictor_single(x):\n",
    "    theta0 = 1\n",
    "    theta1 = 1\n",
    "    return theta0 + theta1 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_predictor(x):\n",
    "    x = np.asarray(x)\n",
    "    predictions = correct_predictor_single(x)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6]\n",
      "[5, 6]\n"
     ]
    }
   ],
   "source": [
    "yCorrect = correct_predictor(Xte)\n",
    "print(Yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above shows, my \"obvious\" statement was correct. (I'm just modeling it to predict my test data, nothing else. Or else would be extremely overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_predictor(x, theta):\n",
    "    x = np.matrix(x)\n",
    "    x = x.T\n",
    "    x = np.insert(x, 0, 1, axis=1)\n",
    "    theta = np.matrix(theta)\n",
    "    theta = theta.T\n",
    "    return np.matmul(x, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "y = naive_predictor([1,2], [1,1])\n",
    "print(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a naive predictor that uses matrix multiplication as opposed to standard computation, which will be used for prediction. As is demonstrated, multiple elements can be predicted at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_classifier:\n",
    "    \n",
    "    theta = [0, 0]\n",
    "    alpha = 0.01\n",
    "    epoch = 300\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return naive_predictor(x, self.theta)\n",
    "    \n",
    "    def train(self, Xtr, Ytr):\n",
    "        Ytr = np.matrix(Ytr)\n",
    "        Xtr = np.matrix(Xtr)\n",
    "        \n",
    "        Ytr = Ytr.T\n",
    "        Yhat = self.predict(Xtr)\n",
    "        self.gradient_des(Xtr, Yhat, Ytr)\n",
    "        \n",
    "    def cost_fcn(self, Yhat, Ytr):\n",
    "        squaredError = (Yhat - Ytr)^2\n",
    "        b = 1/(Yhat.size*2);\n",
    "        return b * np.sum(squaredError, 0);\n",
    "    \n",
    "    def gradient_des(self, Xtr, Yhat, Ytr):\n",
    "        size = Xtr.shape[0]\n",
    "        diff = Yhat - Ytr\n",
    "        sumDiff = np.sum(diff)\n",
    "        \n",
    "        \n",
    "        weights = np.ones( (Xtr.shape[1], Xtr.shape[0]) ) \n",
    "        weights = weights * sumDiff\n",
    "        \n",
    "        self.theta[0] = self.theta[0] - (self.alpha * (1/size) * sumDiff * 1)\n",
    "        print(self.theta[0])\n",
    "        print(self.alpha)\n",
    "        print(1/size)\n",
    "        print(sumDiff)\n",
    "        #diffDerivative = np.matmul(diff, Xtr).diagonal()\n",
    "        #diffDerivative = diffDerivative * self.alpha / Xtr.size\n",
    "        #print(diffDerivative)\n",
    "        #print(self.theta)\n",
    "        #self.theta = self.theta - diffDerivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09\n",
      "0.01\n",
      "1.0\n",
      "-9\n"
     ]
    }
   ],
   "source": [
    "model = linear_classifier()\n",
    "model.predict([1,2])\n",
    "model.train(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
