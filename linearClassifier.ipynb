{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Objective\n",
    "I'm going to create a linear regression classifier based on Andrew Ng's teachings before the linear algebra review... so hopefully that doesn't bite me in the butt. It's going to be using batch gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details\n",
    "- Scalable number of features (test up to 3)\n",
    "- Gradient Descent (batch)\n",
    "- Cost function (squared error cost function)\n",
    "- Regression classifier only\n",
    "- Manual learning rate (alpha)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "1) ~~I'm going to first import a standardized linear regression classifier from tensorflow, and configure it appropriately, then ensure i'm getting the proper output.~~ I will create the static training data and testing data.\n",
    "\n",
    "2) I'm going to build my version of the classifier in python, and work on it until I get the proper results.\n",
    "\n",
    "(#Test-driven development?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Results\n",
    "1) Greater Python familiarity\n",
    "\n",
    "~~2) Greater Tensorflow familiarity~~\n",
    "\n",
    "3) Greater fundamental ML familiarity\n",
    "\n",
    "4) Resume worthy material\n",
    "\n",
    "*I will be editing my material minimally to preserve the jouney of my project, think of it as a story =]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with importing everything needed\n",
    "from __future__ import division\n",
    "#import tensorflow as tf # for bonafide classifiers\n",
    "import numpy as np # matrices and calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f8c49b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1109509e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating data\n",
    "X = [1, 2, 3, 4, 5]\n",
    "Y = [2, 3, 4, 5, 6]\n",
    "Xtr = X[0:3]\n",
    "Ytr = Y[0:3]\n",
    "Xte = X[3:5]\n",
    "Yte = Y[3:5]\n",
    "\n",
    "import matplotlib.pyplot as plt # to visualize data, I know it's bad practice just documenting the journey\n",
    "plt.figure(1)\n",
    "plt.title(\"All data\")\n",
    "plt.scatter(Xtr,Ytr, label=\"training\")\n",
    "plt.scatter(Xte,Yte, label=\"testing\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title(\"Perfect predictor for dataset\")\n",
    "plt.scatter(Xtr,Ytr, label=\"training\")\n",
    "plt.scatter(Xte,Yte, label=\"testing\")\n",
    "plt.plot(X,Y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "At this point (after 3hr of trying to brute force Tensorflow instead of understanding it) I realized how much time it was going to take to dive deep into Tensorflow. So instead decided to choose another option to save time. Keras didn't do the trick either- but at least I got it working. I thought if I just made one layer it might act like a linear classifier, but I was very very wrong ...\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that perfect linear predictor would have the weights of: theta0 = 1, theta1 = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_predictor_single(x):\n",
    "    theta0 = 1\n",
    "    theta1 = 1\n",
    "    return theta0 + theta1 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_predictor(x):\n",
    "    x = np.asarray(x)\n",
    "    predictions = correct_predictor_single(x)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6]\n",
      "[5, 6]\n"
     ]
    }
   ],
   "source": [
    "yCorrect = correct_predictor(Xte)\n",
    "print(Yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above shows, my \"obvious\" statement was correct. (I'm just modeling it to predict my test data, nothing else. Or else would be extremely overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_predictor(x, theta):\n",
    "    x = np.matrix(x)\n",
    "    x = x.T\n",
    "    x = np.insert(x, 0, 1, axis=1)\n",
    "    theta = np.matrix(theta)\n",
    "    theta = theta.T\n",
    "    return np.matmul(x, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "y = naive_predictor([1,2], [1,1])\n",
    "print(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a naive predictor that uses matrix multiplication as opposed to standard computation, which will be used for prediction. As is demonstrated, multiple elements can be predicted at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_classifier:\n",
    "    \n",
    "    theta = [0, 0]\n",
    "    alpha = 0.01\n",
    "    epoch = 300\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return naive_predictor(x, self.theta)\n",
    "    \n",
    "    def train(self, Xtr, Ytr):\n",
    "        Ytr = np.matrix(Ytr)\n",
    "        Ytr = Ytr.T\n",
    "        \n",
    "        Yhat = self.predict(Xtr)\n",
    "        J = self.cost_fcn(Yhat, Ytr)\n",
    "        \n",
    "        self.gradient_des(J)\n",
    "        \n",
    "    def cost_fcn(self, Yhat, Ytr):\n",
    "        squaredError = (Yhat - Ytr)^2\n",
    "        b = 1/(Yhat.size*2);\n",
    "        return b * np.sum(squaredError, 0);\n",
    "    \n",
    "    def gradient_des(self, J):\n",
    "        print(J[0][0])\n",
    "        self.theta[0] = self.theta[0] - ( self.alpha * derivative(J, 1.0, dx=self.theta[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.16666667]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'matrix' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-461d5e777995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-80-a9919753fdf6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, Xtr, Ytr)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_fcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_des\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcost_fcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-a9919753fdf6>\u001b[0m in \u001b[0;36mgradient_des\u001b[0;34m(self, J)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgradient_des\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mderivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/misc/common.py\u001b[0m in \u001b[0;36mderivative\u001b[0;34m(func, x0, dx, n, args, order)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morder\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'matrix' object is not callable"
     ]
    }
   ],
   "source": [
    "model = linear_classifier()\n",
    "model.predict([1,2])\n",
    "model.train(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
